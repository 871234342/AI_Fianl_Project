Test case: 10 Batch size: 1024 Number of epochs: 30 Learning rate: 0.01 Weight decay: 0 LR_step: 12
Compose([
  RandomRotate90(always_apply=False, p=0.5),
  Flip(always_apply=False, p=0.5),
  OneOf([
    CLAHE(always_apply=False, p=0.5, clip_limit=(1, 2), tile_grid_size=(8, 8)),
    IAASharpen(always_apply=False, p=0.5, alpha=(0.2, 0.5), lightness=(0.5, 1.0)),
    IAAEmboss(always_apply=False, p=0.5, alpha=(0.2, 0.5), strength=(0.2, 0.7)),
    RandomBrightnessContrast(always_apply=False, p=0.5, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True),
    ImageCompression(always_apply=False, p=0.5, quality_lower=99, quality_upper=100, compression_type=0),
    Blur(always_apply=False, p=0.5, blur_limit=(3, 7)),
    GaussNoise(always_apply=False, p=0.5, var_limit=(10.0, 50.0)),
  ], p=0.5),
  HueSaturationValue(always_apply=False, p=0.5, hue_shift_limit=(-20, 20), sat_shift_limit=(-30, 30), val_shift_limit=(-20, 20)),
  Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})
Fold 0
private: 0.8749 public: 0.8897
002: train loss: 0.00026147 acc: 0.8902, val loss: 0.00024746 acc:0.9008
004: train loss: 0.00021215 acc: 0.9145, val loss: 0.00021007 acc:0.9167
006: train loss: 0.00018922 acc: 0.9252, val loss: 0.00019009 acc:0.9269
008: train loss: 0.00018326 acc: 0.9272, val loss: 0.00018576 acc:0.9269
010: train loss: 0.00018129 acc: 0.9288, val loss: 0.00018251 acc:0.9290
012: train loss: 0.00018002 acc: 0.9288, val loss: 0.00018368 acc:0.9286
014: train loss: 0.00018027 acc: 0.9287, val loss: 0.00018353 acc:0.9290
016: train loss: 0.00017892 acc: 0.9294, val loss: 0.00018460 acc:0.9296
018: train loss: 0.00017917 acc: 0.9294, val loss: 0.00018244 acc:0.9300
020: train loss: 0.00017885 acc: 0.9286, val loss: 0.00018621 acc:0.9297
022: train loss: 0.00017908 acc: 0.9290, val loss: 0.00018367 acc:0.9296
024: train loss: 0.00017892 acc: 0.9294, val loss: 0.00018514 acc:0.9277
026: train loss: 0.00017808 acc: 0.9300, val loss: 0.00018558 acc:0.9275
028: train loss: 0.00017840 acc: 0.9292, val loss: 0.00018684 acc:0.9283
030: train loss: 0.00017821 acc: 0.9297, val loss: 0.00018686 acc:0.9265
Best accuracy: 0.9303 at epoch23
Fold 1
002: train loss: 0.00025985 acc: 0.8909, val loss: 0.00024401 acc:0.9022
004: train loss: 0.00021234 acc: 0.9144, val loss: 0.00021031 acc:0.9180
006: train loss: 0.00019003 acc: 0.9244, val loss: 0.00019418 acc:0.9241
008: train loss: 0.00018341 acc: 0.9272, val loss: 0.00018836 acc:0.9275
010: train loss: 0.00018178 acc: 0.9279, val loss: 0.00018744 acc:0.9285
012: train loss: 0.00017959 acc: 0.9292, val loss: 0.00018693 acc:0.9269
014: train loss: 0.00017768 acc: 0.9298, val loss: 0.00018834 acc:0.9272
016: train loss: 0.00017847 acc: 0.9292, val loss: 0.00018231 acc:0.9303
018: train loss: 0.00017960 acc: 0.9292, val loss: 0.00018412 acc:0.9282
020: train loss: 0.00017918 acc: 0.9289, val loss: 0.00018887 acc:0.9264
022: train loss: 0.00017803 acc: 0.9299, val loss: 0.00018512 acc:0.9291
024: train loss: 0.00017809 acc: 0.9294, val loss: 0.00018665 acc:0.9296
026: train loss: 0.00017830 acc: 0.9296, val loss: 0.00018474 acc:0.9277
028: train loss: 0.00017804 acc: 0.9292, val loss: 0.00018956 acc:0.9266
030: train loss: 0.00017897 acc: 0.9290, val loss: 0.00018631 acc:0.9281
Best accuracy: 0.9305 at epoch19
Fold 2
002: train loss: 0.00026021 acc: 0.8908, val loss: 0.00024573 acc:0.9017
004: train loss: 0.00021441 acc: 0.9133, val loss: 0.00020398 acc:0.9211
006: train loss: 0.00019096 acc: 0.9245, val loss: 0.00018838 acc:0.9272
008: train loss: 0.00018367 acc: 0.9273, val loss: 0.00018415 acc:0.9260
010: train loss: 0.00018173 acc: 0.9280, val loss: 0.00018208 acc:0.9292
012: train loss: 0.00017944 acc: 0.9290, val loss: 0.00017766 acc:0.9324
014: train loss: 0.00018009 acc: 0.9285, val loss: 0.00018268 acc:0.9303
016: train loss: 0.00018093 acc: 0.9286, val loss: 0.00018074 acc:0.9293
018: train loss: 0.00017913 acc: 0.9294, val loss: 0.00017708 acc:0.9302
020: train loss: 0.00017968 acc: 0.9289, val loss: 0.00017951 acc:0.9312
022: train loss: 0.00017861 acc: 0.9293, val loss: 0.00018335 acc:0.9287
024: train loss: 0.00018002 acc: 0.9290, val loss: 0.00018263 acc:0.9291
026: train loss: 0.00018002 acc: 0.9290, val loss: 0.00018137 acc:0.9289
028: train loss: 0.00017952 acc: 0.9292, val loss: 0.00018359 acc:0.9302
030: train loss: 0.00018041 acc: 0.9283, val loss: 0.00018018 acc:0.9285
Best accuracy: 0.9324 at epoch12
Fold 3
002: train loss: 0.00026335 acc: 0.8892, val loss: 0.00024915 acc:0.8968
004: train loss: 0.00021332 acc: 0.9131, val loss: 0.00021144 acc:0.9151
006: train loss: 0.00019040 acc: 0.9244, val loss: 0.00019302 acc:0.9257
008: train loss: 0.00018392 acc: 0.9276, val loss: 0.00019062 acc:0.9259
010: train loss: 0.00018216 acc: 0.9283, val loss: 0.00018387 acc:0.9295
012: train loss: 0.00018130 acc: 0.9287, val loss: 0.00018411 acc:0.9281
014: train loss: 0.00017969 acc: 0.9292, val loss: 0.00018614 acc:0.9288
016: train loss: 0.00017974 acc: 0.9289, val loss: 0.00018602 acc:0.9286
018: train loss: 0.00018011 acc: 0.9285, val loss: 0.00018528 acc:0.9284
020: train loss: 0.00018044 acc: 0.9286, val loss: 0.00018220 acc:0.9299
022: train loss: 0.00017910 acc: 0.9288, val loss: 0.00018242 acc:0.9276
024: train loss: 0.00017997 acc: 0.9286, val loss: 0.00018967 acc:0.9271
026: train loss: 0.00017932 acc: 0.9291, val loss: 0.00018439 acc:0.9291
028: train loss: 0.00018028 acc: 0.9286, val loss: 0.00018684 acc:0.9274
030: train loss: 0.00018032 acc: 0.9290, val loss: 0.00018553 acc:0.9285
Best accuracy: 0.9301 at epoch13
Fold 4
002: train loss: 0.00026462 acc: 0.8886, val loss: 0.00024690 acc:0.9000
004: train loss: 0.00021446 acc: 0.9133, val loss: 0.00021156 acc:0.9175
006: train loss: 0.00019295 acc: 0.9233, val loss: 0.00019391 acc:0.9249
008: train loss: 0.00018504 acc: 0.9268, val loss: 0.00019028 acc:0.9271
010: train loss: 0.00018300 acc: 0.9273, val loss: 0.00018870 acc:0.9265
012: train loss: 0.00018134 acc: 0.9285, val loss: 0.00018765 acc:0.9282
014: train loss: 0.00018184 acc: 0.9282, val loss: 0.00018725 acc:0.9278
016: train loss: 0.00018137 acc: 0.9286, val loss: 0.00018527 acc:0.9292
018: train loss: 0.00017949 acc: 0.9293, val loss: 0.00018886 acc:0.9277
020: train loss: 0.00018017 acc: 0.9288, val loss: 0.00018891 acc:0.9266
022: train loss: 0.00017963 acc: 0.9291, val loss: 0.00018379 acc:0.9307
024: train loss: 0.00018073 acc: 0.9289, val loss: 0.00018826 acc:0.9289
026: train loss: 0.00018074 acc: 0.9289, val loss: 0.00018651 acc:0.9290
028: train loss: 0.00018030 acc: 0.9285, val loss: 0.00018645 acc:0.9281
030: train loss: 0.00018130 acc: 0.9285, val loss: 0.00018754 acc:0.9273
Best accuracy: 0.9307 at epoch22
Fold 5
002: train loss: 0.00026026 acc: 0.8912, val loss: 0.00024038 acc:0.9033
004: train loss: 0.00021444 acc: 0.9133, val loss: 0.00020323 acc:0.9216
006: train loss: 0.00019123 acc: 0.9244, val loss: 0.00018573 acc:0.9260
008: train loss: 0.00018541 acc: 0.9262, val loss: 0.00018384 acc:0.9287
010: train loss: 0.00018255 acc: 0.9272, val loss: 0.00018061 acc:0.9302
012: train loss: 0.00018233 acc: 0.9280, val loss: 0.00018186 acc:0.9284
014: train loss: 0.00018141 acc: 0.9282, val loss: 0.00017849 acc:0.9316
016: train loss: 0.00018129 acc: 0.9282, val loss: 0.00018164 acc:0.9297
018: train loss: 0.00018035 acc: 0.9285, val loss: 0.00018038 acc:0.9306
020: train loss: 0.00018108 acc: 0.9283, val loss: 0.00018054 acc:0.9302
022: train loss: 0.00018151 acc: 0.9278, val loss: 0.00018005 acc:0.9296
024: train loss: 0.00018006 acc: 0.9291, val loss: 0.00018095 acc:0.9307
026: train loss: 0.00018108 acc: 0.9288, val loss: 0.00018170 acc:0.9302
028: train loss: 0.00017992 acc: 0.9286, val loss: 0.00018275 acc:0.9311
030: train loss: 0.00018145 acc: 0.9283, val loss: 0.00018045 acc:0.9300
Best accuracy: 0.9322 at epoch17
Fold 6
002: train loss: 0.00026086 acc: 0.8908, val loss: 0.00025568 acc:0.8955
004: train loss: 0.00021332 acc: 0.9134, val loss: 0.00021950 acc:0.9138
006: train loss: 0.00019008 acc: 0.9243, val loss: 0.00019636 acc:0.9242
008: train loss: 0.00018324 acc: 0.9272, val loss: 0.00019219 acc:0.9245
010: train loss: 0.00018186 acc: 0.9279, val loss: 0.00019196 acc:0.9266
012: train loss: 0.00018012 acc: 0.9279, val loss: 0.00018972 acc:0.9275
014: train loss: 0.00017987 acc: 0.9289, val loss: 0.00019023 acc:0.9259
016: train loss: 0.00017860 acc: 0.9298, val loss: 0.00019101 acc:0.9252
018: train loss: 0.00017915 acc: 0.9292, val loss: 0.00018734 acc:0.9276
020: train loss: 0.00017896 acc: 0.9297, val loss: 0.00019482 acc:0.9254
022: train loss: 0.00017916 acc: 0.9292, val loss: 0.00018753 acc:0.9268
024: train loss: 0.00017891 acc: 0.9294, val loss: 0.00018768 acc:0.9268
026: train loss: 0.00017961 acc: 0.9294, val loss: 0.00018727 acc:0.9287
028: train loss: 0.00017901 acc: 0.9292, val loss: 0.00019046 acc:0.9251
030: train loss: 0.00018045 acc: 0.9292, val loss: 0.00019179 acc:0.9254
Best accuracy: 0.9287 at epoch26
Fold 7
002: train loss: 0.00026320 acc: 0.8900, val loss: 0.00024253 acc:0.9021
004: train loss: 0.00021362 acc: 0.9136, val loss: 0.00020495 acc:0.9208
006: train loss: 0.00018930 acc: 0.9244, val loss: 0.00018668 acc:0.9271
008: train loss: 0.00018430 acc: 0.9272, val loss: 0.00018481 acc:0.9286
010: train loss: 0.00018197 acc: 0.9277, val loss: 0.00018354 acc:0.9276
012: train loss: 0.00018096 acc: 0.9282, val loss: 0.00018546 acc:0.9272
014: train loss: 0.00018016 acc: 0.9286, val loss: 0.00018057 acc:0.9294
016: train loss: 0.00018092 acc: 0.9288, val loss: 0.00018263 acc:0.9315
018: train loss: 0.00018078 acc: 0.9285, val loss: 0.00018039 acc:0.9290
020: train loss: 0.00017911 acc: 0.9294, val loss: 0.00018117 acc:0.9309
022: train loss: 0.00017924 acc: 0.9293, val loss: 0.00017927 acc:0.9297
024: train loss: 0.00017964 acc: 0.9289, val loss: 0.00018365 acc:0.9286
026: train loss: 0.00018105 acc: 0.9283, val loss: 0.00018270 acc:0.9291
028: train loss: 0.00017851 acc: 0.9290, val loss: 0.00018104 acc:0.9304
030: train loss: 0.00017884 acc: 0.9297, val loss: 0.00018408 acc:0.9291
Best accuracy: 0.9326 at epoch27
Fold 8
002: train loss: 0.00026379 acc: 0.8892, val loss: 0.00024386 acc:0.9026
004: train loss: 0.00021491 acc: 0.9126, val loss: 0.00020932 acc:0.9178
006: train loss: 0.00019040 acc: 0.9242, val loss: 0.00018940 acc:0.9272
008: train loss: 0.00018468 acc: 0.9269, val loss: 0.00018644 acc:0.9278
010: train loss: 0.00018092 acc: 0.9283, val loss: 0.00018435 acc:0.9301
012: train loss: 0.00018106 acc: 0.9281, val loss: 0.00018365 acc:0.9286
014: train loss: 0.00018030 acc: 0.9285, val loss: 0.00018246 acc:0.9301
016: train loss: 0.00017943 acc: 0.9291, val loss: 0.00018768 acc:0.9283
018: train loss: 0.00018036 acc: 0.9289, val loss: 0.00018724 acc:0.9269
020: train loss: 0.00017944 acc: 0.9295, val loss: 0.00018442 acc:0.9285
022: train loss: 0.00018003 acc: 0.9287, val loss: 0.00018599 acc:0.9291
024: train loss: 0.00017979 acc: 0.9291, val loss: 0.00017997 acc:0.9316
026: train loss: 0.00017957 acc: 0.9294, val loss: 0.00018123 acc:0.9305
028: train loss: 0.00018101 acc: 0.9278, val loss: 0.00018449 acc:0.9300
030: train loss: 0.00017973 acc: 0.9287, val loss: 0.00017869 acc:0.9304
Best accuracy: 0.9316 at epoch24
Fold 9
002: train loss: 0.00026363 acc: 0.8888, val loss: 0.00024280 acc:0.9034
004: train loss: 0.00021509 acc: 0.9129, val loss: 0.00020867 acc:0.9185
006: train loss: 0.00019041 acc: 0.9241, val loss: 0.00019032 acc:0.9269
008: train loss: 0.00018428 acc: 0.9270, val loss: 0.00018285 acc:0.9285
010: train loss: 0.00018269 acc: 0.9275, val loss: 0.00018451 acc:0.9292
012: train loss: 0.00018151 acc: 0.9288, val loss: 0.00018356 acc:0.9276
014: train loss: 0.00018092 acc: 0.9285, val loss: 0.00018469 acc:0.9303
016: train loss: 0.00018016 acc: 0.9285, val loss: 0.00017973 acc:0.9306
018: train loss: 0.00018031 acc: 0.9292, val loss: 0.00018363 acc:0.9289
020: train loss: 0.00018027 acc: 0.9290, val loss: 0.00018622 acc:0.9275
022: train loss: 0.00017959 acc: 0.9289, val loss: 0.00018357 acc:0.9306
024: train loss: 0.00017855 acc: 0.9291, val loss: 0.00018333 acc:0.9314
026: train loss: 0.00018038 acc: 0.9289, val loss: 0.00017974 acc:0.9303
028: train loss: 0.00018085 acc: 0.9288, val loss: 0.00018378 acc:0.9291
030: train loss: 0.00018024 acc: 0.9285, val loss: 0.00018268 acc:0.9305
Best accuracy: 0.9314 at epoch24
